{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43451172-9e7b-43bd-adec-80b7e314de34",
   "metadata": {},
   "source": [
    "## NLP - Lesson 5 - LLM based Sentiment Analysis\n",
    "\n",
    "Keeping up with the current trend, LLMs is the hottest thing in the AI industry right now. This is a basic notebook which can be used to learn how to read and use any pre-saved LLM from the **hugging face** library - **Transformers**. I have used the below hugging face article to read about the usage of a few pre-saved LLMs. Since our problem is to classify disaster based tweets in POSITIVE or NEGATIVE (disaster and no-disaster), we will be using an LLM trained on tweets to classify them as sentiments. Now let's start with the notebook.\n",
    "\n",
    "Source - [Hugging-Face-Article](https://huggingface.co/blog/sentiment-analysis-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded0c98a-5022-4b33-a9ab-16284db85c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e568048b-cd2e-4b84-8c29-5552137ecd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46477b7-5e78-456b-bee8-3cf498f22302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7df4df-5202-4c4d-bde9-fd7768ee5034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POS', 'score': 0.9916695356369019},\n",
       " {'label': 'NEG', 'score': 0.9806600213050842}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "specific_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857089e0-83ed-4ab8-95f0-f4ccc4e6bf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5709, 5), (1904, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=100)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d5939f-14a0-41d3-89fe-93687f23f4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>4866</td>\n",
       "      <td>explode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn How I Gained Access To The Secrets Of Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>10490</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>Vail Valley</td>\n",
       "      <td>We should all have a fire safety plan. RT @Mat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>6979</td>\n",
       "      <td>massacre</td>\n",
       "      <td>Cimerak - Pangandaran</td>\n",
       "      <td>Review: Dude Bro Party Massacre III http://t.c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   keyword               location  \\\n",
       "3398   4866   explode                    NaN   \n",
       "7330  10490  wildfire            Vail Valley   \n",
       "4903   6979  massacre  Cimerak - Pangandaran   \n",
       "\n",
       "                                                   text  target  \n",
       "3398  Learn How I Gained Access To The Secrets Of Th...       0  \n",
       "7330  We should all have a fire safety plan. RT @Mat...       0  \n",
       "4903  Review: Dude Bro Party Massacre III http://t.c...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0442ac30-ab51-4d10-9a81-aaad0ff3a622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>5680</td>\n",
       "      <td>floods</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>Typhoon Soudelor approaches after 7 killed 2 m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>2659</td>\n",
       "      <td>crush</td>\n",
       "      <td>EastAtlanta ??#WestGeorgia'18</td>\n",
       "      <td>WCE I can't even lie even tho I can't stand he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>7514</td>\n",
       "      <td>oil%20spill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SYD traffic HAZARD Oil spill - BANKSTOWN Stace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword                       location  \\\n",
       "3999  5680       floods                 Estados Unidos   \n",
       "1849  2659        crush  EastAtlanta ??#WestGeorgia'18   \n",
       "5254  7514  oil%20spill                            NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "3999  Typhoon Soudelor approaches after 7 killed 2 m...       1  \n",
       "1849  WCE I can't even lie even tho I can't stand he...       0  \n",
       "5254  SYD traffic HAZARD Oil spill - BANKSTOWN Stace...       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0bac13-456a-4e82-9f33-c8c07350ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 27.1 s, total: 2min 37s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train['sentiment_distilbert'] = train['text'].map(lambda x : sentiment_pipeline(x)[0]['label'])\n",
    "test['sentiment_distilbert'] = test['text'].map(lambda x : sentiment_pipeline(x)[0]['label'])\n",
    "train['sentiment_bertweet']= train['text'].map(lambda x : specific_model(x)[0]['label'])\n",
    "test['sentiment_bertweet']= test['text'].map(lambda x : specific_model(x)[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4edc4caf-b20f-4bbf-a78a-6942b0877b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_distilbert\n",
      "NEGATIVE    4810\n",
      "POSITIVE     899\n",
      "Name: count, dtype: int64 sentiment_distilbert\n",
      "NEGATIVE    1586\n",
      "POSITIVE     318\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['sentiment_distilbert'].value_counts(), test['sentiment_distilbert'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb434c19-1c07-437d-974b-0aa33703c8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_bertweet\n",
      "NEU    2606\n",
      "NEG    2357\n",
      "POS     746\n",
      "Name: count, dtype: int64 sentiment_bertweet\n",
      "NEU    877\n",
      "NEG    762\n",
      "POS    265\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['sentiment_bertweet'].value_counts(), test['sentiment_bertweet'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce273f7-df9d-4d2b-9b44-68e4cc8200bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred_distilbert'] = np.where(train['sentiment_distilbert']=='NEGATIVE',1,0)\n",
    "test['pred_distilbert'] = np.where(test['sentiment_distilbert']=='NEGATIVE',1,0)\n",
    "train['pred_bertweet'] = np.where(train['sentiment_bertweet']=='POS',0,1)\n",
    "test['pred_bertweet'] = np.where(test['sentiment_bertweet']=='POS',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18be9768-3350-4f57-90a0-ddf72849bff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################################################################\n",
      "Precision for Train Distilbert :  0.4602910602910603\n",
      "Recall for Train Distilbert :  0.8941841680129241\n",
      "F1 Score for Train Distilbert :  0.6077408729069448\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "Precision for Test Distilbert :  0.44703656998738966\n",
      "Recall for Test Distilbert :  0.8918238993710692\n",
      "F1 Score for Test Distilbert :  0.5955480890382192\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "Precision for Train Bertweet :  0.47209349183961313\n",
      "Recall for Train Bertweet :  0.9462843295638126\n",
      "F1 Score for Train Bertweet :  0.6299233767979567\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "Precision for Test Bertweet :  0.45332519829164125\n",
      "Recall for Test Bertweet :  0.9345911949685535\n",
      "F1 Score for Test Bertweet :  0.610517666392769\n",
      "#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(y, pred, dataset='given', ret_metrics=False):\n",
    "    print(\"#\"*125)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    # print(f\"AUC for {dataset} : \",auc)\n",
    "    print(f\"Precision for {dataset} : \",prec)\n",
    "    print(f\"Recall for {dataset} : \",rec)\n",
    "    print(f\"F1 Score for {dataset} : \",f1)\n",
    "    print(\"#\"*125)\n",
    "    if ret_metrics:\n",
    "        return auc, prec, rec, f1\n",
    "\n",
    "get_metrics(train['target'],train['pred_distilbert'],dataset='Train Distilbert')\n",
    "get_metrics(test['target'],test['pred_distilbert'],dataset='Test Distilbert')\n",
    "get_metrics(train['target'],train['pred_bertweet'],dataset='Train Bertweet')\n",
    "get_metrics(test['target'],test['pred_bertweet'],dataset='Test Bertweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870774ce-e7d8-4f76-8be2-3117c2bd954b",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We see that a pre-trained LLM could not get a good precision but still did very well with respect to recall. If we adjust thresholds for probabilities to optimise and balance between precision and recall, maybe we will be able to reach around 80%. In the next notebook, we will be building a PEFT (Parameter Efficient Fine Tuning) model which will be trained on this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c35c6-adc2-42f2-a59d-7eb753933ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
