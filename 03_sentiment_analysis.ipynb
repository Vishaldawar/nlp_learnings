{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132e0747-5b4e-45a0-a7a5-7c284c6c9df5",
   "metadata": {},
   "source": [
    "## NLP - Lesson 3 - Sentiment Analysis\n",
    "\n",
    "In Natural Language Processing, the idea is to learn patterns and form insights from textual data using a computer. But as computers cannot understand the text directly, we have to convert the text into numerical data which then can be used as an input to traditional and modern models. Machine learning algorithms can handle any dimension of textual data when converted to numerical data using techniques like word embeddings, for example word2vec. I am writing this notebook to teach myself, and possibly others, these techniques from scratch and also using famous python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbf48b-958f-4e7f-ac80-728254f57dad",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d308e413-92d8-40e4-86ea-58689d531748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2aa0c3b-8476-4117-9649-30c8bc3731d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, auc\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a172eb69-bb70-499e-8ddc-182dd00dbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e14dc1b-82c1-463b-a489-08ff2b542ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe542ea-f9ee-428f-b973-34a5d2b4242f",
   "metadata": {},
   "source": [
    "### Data - Twitter Disaster Classification\n",
    "\n",
    "I have downloaded this data from Kaggle from the **Twitter Disaster Classification** competition.\n",
    "Source - [Twitter Disaster Classification](https://www.kaggle.com/competitions/nlp-getting-started/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06dbd66-8c88-43b6-977c-c9688dbc96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "\n",
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134c80c6-3e92-4721-8ca9-9b002119ca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355c1252-1a49-4df8-b62f-5919b8652c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdfeed26-78d2-4b0d-9d41-9ae4ab416c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          7613\n",
       "keyword      221\n",
       "location    3341\n",
       "text        7503\n",
       "target         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4608bae-8d44-417c-8612-49c87c0530dc",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "\n",
    "Let's split the data into train-test-split. We won't be performing EDA in this notebook as if we have already conducted some basic EDA in [00_vectorizer](https://github.com/Vishaldawar/nlp_learnings/blob/main/00_vectorizer.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "311f940e-f800-4e1b-8565-e5b80cf1badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5709, 5), (1904, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.25, random_state=100)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad250715-edff-4030-befa-80687f691365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43370117358556665, 0.4175420168067227, 0.4296597924602653)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].mean(), test['target'].mean(), data['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84674716-9822-41cd-9673-a490a44c9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelling:\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, target):\n",
    "        self.train_X = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_X = test_x\n",
    "        self.test_y = test_x\n",
    "        self.target = target\n",
    "\n",
    "    def train_model(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clf.fit(self.train_X, self.train_y)\n",
    "\n",
    "    def get_metrics(self, X, y, dataset='given', ret_metrics=False):\n",
    "        print(\"#\"*125)\n",
    "        self.proba = self.clf.predict_proba(X)[:,1]\n",
    "        self.pred = self.clf.predict(X)\n",
    "        auc = roc_auc_score(y, self.proba)\n",
    "        prec = precision_score(y, self.pred)\n",
    "        rec = recall_score(y, self.pred)\n",
    "        f1 = f1_score(y, self.pred)\n",
    "        print(f\"AUC for {dataset} : \",auc)\n",
    "        print(f\"Precision for {dataset} : \",prec)\n",
    "        print(f\"Recall for {dataset} : \",rec)\n",
    "        print(f\"F1 Score for {dataset} : \",f1)\n",
    "        print(\"#\"*125)\n",
    "        if ret_metrics:\n",
    "            return auc, prec, rec, f1\n",
    "\n",
    "    def plot_roc_auc_curve(self, y, pred):\n",
    "        fpr, tpr, threshold = sklearn.metrics.roc_curve(y, pred)\n",
    "        roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "        \n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc68d62-5f68-46d8-bd69-9c2ff602489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row,col):\n",
    "    val = row[col]\n",
    "    val = val.lower() ## removing case sensitivity\n",
    "    val = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'',val) ## removing hyper-link information\n",
    "    val = re.compile(r'[^a-zA-Z0-9]').sub(r' ',val).strip() ## keeping only alpha-numeric data and removing leading and trailing white spaces\n",
    "    return val\n",
    "\n",
    "def vector_clean_text(df):\n",
    "    df['cleaned_text'] = df.apply(clean_text, args = ['text'], axis=1)\n",
    "    return df\n",
    "\n",
    "def tokenize(df):\n",
    "    df['cleaned_text'] = df['cleaned_text'].map(lambda x : x.split(' '))\n",
    "    return df\n",
    "\n",
    "def filter_stopwords(row,col):\n",
    "    word_list = row[col]\n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    filtered_words = [word for word in filtered_words if word.strip() != '']\n",
    "    filtered_words = \" \".join([word for word in filtered_words if len(word) > 3])\n",
    "    return filtered_words\n",
    "\n",
    "def vector_filter_stopwords(df):\n",
    "    df['cleaned_text'] = df.apply(filter_stopwords, args=['cleaned_text'], axis=1)\n",
    "    return df['cleaned_text']\n",
    "\n",
    "\n",
    "clean_text_trans = FunctionTransformer(vector_clean_text)\n",
    "tokenize_trans = FunctionTransformer(tokenize)\n",
    "stopwords_trans = FunctionTransformer(vector_filter_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "927d49da-aafd-46c7-8b33-0ce1f9ae3c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;clean&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function vector_clean_text at 0x3336748b0&gt;)),\n",
       "                (&#x27;tokenize&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function tokenize at 0x333674940&gt;)),\n",
       "                (&#x27;stopwords&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function vector_filter_stopwords at 0x333674ca0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;clean&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function vector_clean_text at 0x3336748b0&gt;)),\n",
       "                (&#x27;tokenize&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function tokenize at 0x333674940&gt;)),\n",
       "                (&#x27;stopwords&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function vector_filter_stopwords at 0x333674ca0&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function vector_clean_text at 0x3336748b0&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function tokenize at 0x333674940&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function vector_filter_stopwords at 0x333674ca0&gt;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('clean',\n",
       "                 FunctionTransformer(func=<function vector_clean_text at 0x3336748b0>)),\n",
       "                ('tokenize',\n",
       "                 FunctionTransformer(func=<function tokenize at 0x333674940>)),\n",
       "                ('stopwords',\n",
       "                 FunctionTransformer(func=<function vector_filter_stopwords at 0x333674ca0>))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_pipe = Pipeline([(\"clean\", clean_text_trans), (\"tokenize\", tokenize_trans), (\"stopwords\", stopwords_trans)])\n",
    "sk_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66b67719-17af-47ab-aa94-a34f7d58e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.copy()\n",
    "train_data['cleaned_text'] = sk_pipe.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb300788-4a30-443b-92fe-403a70d5959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.copy()\n",
    "test_data['cleaned_text'] = sk_pipe.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de73026-54b3-4e4a-a134-14a7aba38701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>4866</td>\n",
       "      <td>explode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn How I Gained Access To The Secrets Of The Top Earners &amp;amp; Used Them To Explode My Home Business Here: http://t.co/SGXP1U5OL1 Please #RT</td>\n",
       "      <td>0</td>\n",
       "      <td>learn gained access secrets earners used explode home business please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>10490</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>Vail Valley</td>\n",
       "      <td>We should all have a fire safety plan. RT @Matt_Kroschel: MOCK WILDFIRE near #Vail as agencies prepare for the worst. http://t.co/SWwyLRk0fv</td>\n",
       "      <td>0</td>\n",
       "      <td>fire safety plan matt kroschel mock wildfire near vail agencies prepare worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>6979</td>\n",
       "      <td>massacre</td>\n",
       "      <td>Cimerak - Pangandaran</td>\n",
       "      <td>Review: Dude Bro Party Massacre III http://t.co/f0WQlobOoy by Patrick BromleyThe title sa  http://t.co/THpBDPdj35</td>\n",
       "      <td>0</td>\n",
       "      <td>review dude party massacre patrick bromleythe title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>9112</td>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>//./../.. Pic of 16yr old PKK suicide bomber who detonated bomb in Turkey Army trench released http://t.co/Sj57BoKsiB -/</td>\n",
       "      <td>1</td>\n",
       "      <td>16yr suicide bomber detonated bomb turkey army trench released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1792</td>\n",
       "      <td>buildings%20on%20fire</td>\n",
       "      <td>Fort Walton Beach, Fl</td>\n",
       "      <td>They are evacuating buildings in that area of State Road 20. We still don't have confirmation of what is on fire.</td>\n",
       "      <td>1</td>\n",
       "      <td>evacuating buildings area state road still confirmation fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2973</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews : Hundreds feared dead after Libyan migrant boat capsizes during rescue Û_ http://t.co/MjoeeBDLXn) http://t.co/fvEn1ex0PS</td>\n",
       "      <td>1</td>\n",
       "      <td>beforeitsnews hundreds feared dead libyan migrant boat capsizes rescue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>5144</td>\n",
       "      <td>fatal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>year charged manslaughter toddler report year charged manslaughter fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>4238</td>\n",
       "      <td>drowned</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>80 tons of cocaine worth 125 million dollars drowned in #Alameda .....now that's a American drought #coke</td>\n",
       "      <td>1</td>\n",
       "      <td>tons cocaine worth million dollars drowned alameda american drought coke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>3124</td>\n",
       "      <td>debris</td>\n",
       "      <td>Hamilton, Ontario Canada</td>\n",
       "      <td>Malaysia seem more certain than France.\\n\\nPlane debris is from missing MH370 http://t.co/eXZnmxbINJ</td>\n",
       "      <td>1</td>\n",
       "      <td>malaysia seem certain france plane debris missing mh370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>10575</td>\n",
       "      <td>windstorm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@blakeshelton DON'T be a FART ??in a WINDSTORM.FOLLOW ME ALREADY. JEEZ.</td>\n",
       "      <td>1</td>\n",
       "      <td>blakeshelton fart windstorm follow already jeez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                keyword                  location  \\\n",
       "3398   4866                explode                       NaN   \n",
       "7330  10490               wildfire               Vail Valley   \n",
       "4903   6979               massacre     Cimerak - Pangandaran   \n",
       "6376   9112         suicide%20bomb                       NaN   \n",
       "1244   1792  buildings%20on%20fire     Fort Walton Beach, Fl   \n",
       "2071   2973                   dead                       NaN   \n",
       "3603   5144                  fatal                       NaN   \n",
       "2947   4238                drowned         San Francisco, CA   \n",
       "2180   3124                 debris  Hamilton, Ontario Canada   \n",
       "7390  10575              windstorm                       NaN   \n",
       "\n",
       "                                                                                                                                                 text  \\\n",
       "3398  Learn How I Gained Access To The Secrets Of The Top Earners &amp; Used Them To Explode My Home Business Here: http://t.co/SGXP1U5OL1 Please #RT   \n",
       "7330     We should all have a fire safety plan. RT @Matt_Kroschel: MOCK WILDFIRE near #Vail as agencies prepare for the worst. http://t.co/SWwyLRk0fv   \n",
       "4903                                Review: Dude Bro Party Massacre III http://t.co/f0WQlobOoy by Patrick BromleyThe title sa  http://t.co/THpBDPdj35   \n",
       "6376                         //./../.. Pic of 16yr old PKK suicide bomber who detonated bomb in Turkey Army trench released http://t.co/Sj57BoKsiB -/   \n",
       "1244                                They are evacuating buildings in that area of State Road 20. We still don't have confirmation of what is on fire.   \n",
       "2071         beforeitsnews : Hundreds feared dead after Libyan migrant boat capsizes during rescue Û_ http://t.co/MjoeeBDLXn) http://t.co/fvEn1ex0PS   \n",
       "3603         11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...   \n",
       "2947                                        80 tons of cocaine worth 125 million dollars drowned in #Alameda .....now that's a American drought #coke   \n",
       "2180                                             Malaysia seem more certain than France.\\n\\nPlane debris is from missing MH370 http://t.co/eXZnmxbINJ   \n",
       "7390                                                                          @blakeshelton DON'T be a FART ??in a WINDSTORM.FOLLOW ME ALREADY. JEEZ.   \n",
       "\n",
       "      target  \\\n",
       "3398       0   \n",
       "7330       0   \n",
       "4903       0   \n",
       "6376       1   \n",
       "1244       1   \n",
       "2071       1   \n",
       "3603       1   \n",
       "2947       1   \n",
       "2180       1   \n",
       "7390       1   \n",
       "\n",
       "                                                                       cleaned_text  \n",
       "3398          learn gained access secrets earners used explode home business please  \n",
       "7330  fire safety plan matt kroschel mock wildfire near vail agencies prepare worst  \n",
       "4903                            review dude party massacre patrick bromleythe title  \n",
       "6376                 16yr suicide bomber detonated bomb turkey army trench released  \n",
       "1244                   evacuating buildings area state road still confirmation fire  \n",
       "2071         beforeitsnews hundreds feared dead libyan migrant boat capsizes rescue  \n",
       "3603       year charged manslaughter toddler report year charged manslaughter fatal  \n",
       "2947       tons cocaine worth million dollars drowned alameda american drought coke  \n",
       "2180                        malaysia seem certain france plane debris missing mh370  \n",
       "7390                                blakeshelton fart windstorm follow already jeez  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315564c-e8ff-4ef5-b04c-7f77894942b8",
   "metadata": {},
   "source": [
    "This shows that the text looks much better. There are no hashtags as we can see in the examples. We have also removed case sensitivity, tokenized the text and then removed the stopwords like (to, and, of etc.). Now we can count occurrences of words to use count vectorizer and TF-IDF vectorizer and implement sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27273955-ca74-44de-b506-096d11b3ced7",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31aa85c7-81a4-4c77-afd0-914610fddde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb0d733-d8d1-477a-844a-b00ff05ed2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 µs, sys: 2 µs, total: 45 µs\n",
      "Wall time: 47 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5709, 1904)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Creating the vocabulary\n",
    "\n",
    "all_texts_train = train_data['cleaned_text'].values\n",
    "all_texts_test = test_data['cleaned_text'].values\n",
    "len(all_texts_train), len(all_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97e112f8-37a1-4b81-b25a-1514119b3a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['learn gained access secrets earners used explode home business please',\n",
       "       'fire safety plan matt kroschel mock wildfire near vail agencies prepare worst',\n",
       "       'review dude party massacre patrick bromleythe title',\n",
       "       '16yr suicide bomber detonated bomb turkey army trench released',\n",
       "       'evacuating buildings area state road still confirmation fire'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac6202e-f1b5-49ec-9427-4526901c36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b7a0cc-ab1e-48e1-9394-f29bc441ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cleaned_text']\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b79df6f1-8aba-44c6-b81e-eb3c4dd44cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "train_x = tfidf.fit_transform(all_texts_train)\n",
    "test_x = tfidf.transform(all_texts_test)\n",
    "train_y = train_data[target]\n",
    "test_y = test_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41090a68-c755-43e8-a577-fce0d86ca760",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=-1, random_state=100)\n",
    "lr_obj = modelling(train_x, train_y, test_x, test_y, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a0b15bb-fffd-4a55-8e4a-42b1773bb7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################################################################\n",
      "AUC for train :  0.9618397238294306\n",
      "Precision for train :  0.953248031496063\n",
      "Recall for train :  0.7823101777059773\n",
      "F1 Score for train :  0.8593611357586513\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "AUC for test :  0.8671282984841009\n",
      "Precision for test :  0.8346213292117465\n",
      "Recall for test :  0.6792452830188679\n",
      "F1 Score for test :  0.7489597780859917\n",
      "#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "lr_obj.train_model(lr)\n",
    "lr_obj.get_metrics(train_x, train_y, dataset='train',ret_metrics=False)\n",
    "lr_obj.get_metrics(test_x, test_y, dataset='test',ret_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eecc1519-c875-41a8-a27f-9db57f106fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_jobs=-1, random_state=100)\n",
    "xgb_obj = modelling(train_x, train_y, test_x, test_y, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f7d8204-c4cb-4acf-abf5-865bab6ccd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################################################################\n",
      "AUC for train :  0.9286385927233644\n",
      "Precision for train :  0.9330117899249732\n",
      "Recall for train :  0.7031502423263328\n",
      "F1 Score for train :  0.8019345923537541\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "AUC for test :  0.8311527751784996\n",
      "Precision for test :  0.8126064735945485\n",
      "Recall for test :  0.6\n",
      "F1 Score for test :  0.6903039073806078\n",
      "#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "xgb_obj.train_model(xgb)\n",
    "xgb_obj.get_metrics(train_x, train_y, dataset='train',ret_metrics=False)\n",
    "xgb_obj.get_metrics(test_x, test_y, dataset='test',ret_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5e20350-14ee-4b52-9607-018ff6847150",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(n_estimators=200, max_depth=8,n_jobs=-1, random_state=100)\n",
    "xgb_obj2 = modelling(train_x, train_y, test_x, test_y, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cebb447-f8b7-4921-8682-480761f629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################################################################\n",
      "AUC for train :  0.969862489362776\n",
      "Precision for train :  0.9591836734693877\n",
      "Recall for train :  0.8162358642972536\n",
      "F1 Score for train :  0.8819550512764565\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "AUC for test :  0.8406037509002955\n",
      "Precision for test :  0.8095975232198143\n",
      "Recall for test :  0.6578616352201258\n",
      "F1 Score for test :  0.7258848022206801\n",
      "#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "xgb_obj2.train_model(xgb2)\n",
    "xgb_obj2.get_metrics(train_x, train_y, dataset='train',ret_metrics=False)\n",
    "xgb_obj2.get_metrics(test_x, test_y, dataset='test',ret_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e63a89-632f-4b1d-b26f-62daf42f91dc",
   "metadata": {},
   "source": [
    "We see that the results are overfitting as we could see in an earlier notebook. Now let's apply word2vec using an existing library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d3eecf1-b9e6-4f09-a25f-132c44623d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['learn gained access secrets earners used explode home business please',\n",
       "       'fire safety plan matt kroschel mock wildfire near vail agencies prepare worst'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8979f38-1725-4141-b488-2e12f24f3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a186d69-b4d0-4a55-8917-6358e419c558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5709"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words = list(map(lambda x: x.split(), all_texts_train))\n",
    "len(training_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c02ad508-2939-43fd-add0-912fdecf6601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire',\n",
       " 'safety',\n",
       " 'plan',\n",
       " 'matt',\n",
       " 'kroschel',\n",
       " 'mock',\n",
       " 'wildfire',\n",
       " 'near',\n",
       " 'vail',\n",
       " 'agencies',\n",
       " 'prepare',\n",
       " 'worst']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae4cde96-4247-48a7-9169-e31166e12a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Length: 12637\n",
      "CPU times: user 259 ms, sys: 6.37 ms, total: 265 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vector_size = 100\n",
    "\n",
    "word2vec_model = word2vec.Word2Vec(training_words,\n",
    "                 vector_size=vector_size,\n",
    "                 workers=8,\n",
    "                 min_count=1)\n",
    "\n",
    "print(\"Vocabulary Length:\", len(word2vec_model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29a04401-2d8e-494e-bf05-011b6b227109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=12637, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ac71f74-ceb8-41f2-9bff-532a8a4812b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv['learn'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6208225-948b-4979-aad8-cb318516bedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('near', 0.44372454285621643), ('wahpeton', 0.4011099636554718), ('going', 0.3980615735054016), ('38pm', 0.3869110345840454), ('defend', 0.3681480586528778)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = word2vec_model.wv.most_similar('learn', topn=5)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b74a032-9529-47b5-b734-d91411f9f0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>4866</td>\n",
       "      <td>explode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn How I Gained Access To The Secrets Of The Top Earners &amp;amp; Used Them To Explode My Home Business Here: http://t.co/SGXP1U5OL1 Please #RT</td>\n",
       "      <td>0</td>\n",
       "      <td>learn gained access secrets earners used explode home business please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>10490</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>Vail Valley</td>\n",
       "      <td>We should all have a fire safety plan. RT @Matt_Kroschel: MOCK WILDFIRE near #Vail as agencies prepare for the worst. http://t.co/SWwyLRk0fv</td>\n",
       "      <td>0</td>\n",
       "      <td>fire safety plan matt kroschel mock wildfire near vail agencies prepare worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>6979</td>\n",
       "      <td>massacre</td>\n",
       "      <td>Cimerak - Pangandaran</td>\n",
       "      <td>Review: Dude Bro Party Massacre III http://t.co/f0WQlobOoy by Patrick BromleyThe title sa  http://t.co/THpBDPdj35</td>\n",
       "      <td>0</td>\n",
       "      <td>review dude party massacre patrick bromleythe title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   keyword               location  \\\n",
       "3398   4866   explode                    NaN   \n",
       "7330  10490  wildfire            Vail Valley   \n",
       "4903   6979  massacre  Cimerak - Pangandaran   \n",
       "\n",
       "                                                                                                                                                 text  \\\n",
       "3398  Learn How I Gained Access To The Secrets Of The Top Earners &amp; Used Them To Explode My Home Business Here: http://t.co/SGXP1U5OL1 Please #RT   \n",
       "7330     We should all have a fire safety plan. RT @Matt_Kroschel: MOCK WILDFIRE near #Vail as agencies prepare for the worst. http://t.co/SWwyLRk0fv   \n",
       "4903                                Review: Dude Bro Party Massacre III http://t.co/f0WQlobOoy by Patrick BromleyThe title sa  http://t.co/THpBDPdj35   \n",
       "\n",
       "      target  \\\n",
       "3398       0   \n",
       "7330       0   \n",
       "4903       0   \n",
       "\n",
       "                                                                       cleaned_text  \n",
       "3398          learn gained access secrets earners used explode home business please  \n",
       "7330  fire safety plan matt kroschel mock wildfire near vail agencies prepare worst  \n",
       "4903                            review dude party massacre patrick bromleythe title  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87f2aeef-1cc8-486e-a259-178bac78da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tokenized_text'] = train_data['cleaned_text'].map(lambda x : x.split())\n",
    "test_data['tokenized_text'] = test_data['cleaned_text'].map(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70333dc2-8b0b-4d49-b1cb-5ed404474b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42163c8-b7f8-495f-b244-397789fe42f5",
   "metadata": {},
   "source": [
    "We will take the mean of embeddings of all the words present in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df80caa6-d9d9-4f42-8818-8abd1ac95f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 391 ms, sys: 2.36 s, total: 2.75 s\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedding_matrix_train = np.zeros([train_data.shape[0],vector_size])\n",
    "for idx, row in train_data.iterrows():\n",
    "    # print(idx)\n",
    "    vec = np.zeros([100,])\n",
    "    c = 0\n",
    "    c1 = 0\n",
    "    for word in row['tokenized_text']:\n",
    "        try:\n",
    "            vec += word2vec_model.wv[word]\n",
    "            c += 1\n",
    "        except:\n",
    "            c1 += 1\n",
    "            print(f\"No embedding for word : {word}, {c1}\")\n",
    "            continue\n",
    "    vec = vec/max(c,1)\n",
    "    embedding_matrix_train[idx] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d42bb86-de0f-4215-befd-daf105e9893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1904, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7fe1e19-197f-4fab-be2a-941ac173ad98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 ms, sys: 1.28 ms, total: 40.8 ms\n",
      "Wall time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedding_matrix_test = np.zeros([test_data.shape[0],vector_size])\n",
    "c1 = 0\n",
    "for idx, row in test_data.iterrows():\n",
    "    # print(idx)\n",
    "    vec = np.zeros([100,])\n",
    "    c = 0\n",
    "    for word in row['tokenized_text']:\n",
    "        try:\n",
    "            vec += word2vec_model.wv[word]\n",
    "            c += 1\n",
    "        except:\n",
    "            c1 += 1\n",
    "            # print(f\"No embedding for word : {word}, {c1}\")\n",
    "            continue\n",
    "    vec = vec/max(c,1)\n",
    "    embedding_matrix_test[idx] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66c5af59-73aa-40e5-9dc7-59f266b78bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5709, 100), (1904, 100))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_train.shape, embedding_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e11f26d0-0634-4342-932f-13585ec9ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_word2vec_model = XGBClassifier(n_estimators=200, max_depth=8,n_jobs=-1, random_state=100)\n",
    "xgb_word2vec_obj = modelling(embedding_matrix_train, train_y, embedding_matrix_test, test_y, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "302421fe-fbd1-4e94-b633-8c841a60e725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################################################################\n",
      "AUC for train :  0.9995690768713394\n",
      "Precision for train :  0.9893964110929854\n",
      "Recall for train :  0.9798061389337641\n",
      "F1 Score for train :  0.984577922077922\n",
      "#############################################################################################################################\n",
      "#############################################################################################################################\n",
      "AUC for test :  0.7818012714724013\n",
      "Precision for test :  0.7128129602356407\n",
      "Recall for test :  0.6088050314465409\n",
      "F1 Score for test :  0.6567164179104478\n",
      "#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "xgb_word2vec_obj.train_model(xgb_word2vec_model)\n",
    "xgb_word2vec_obj.get_metrics(embedding_matrix_train, train_y, dataset='train',ret_metrics=False)\n",
    "xgb_word2vec_obj.get_metrics(embedding_matrix_test, test_y, dataset='test',ret_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f4996-d64d-45d6-b3ae-c65dedc384ba",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can see that through word2vec embeddings, we have pushed the metrics to almost 99% of all metrics being tracked. However, the performance on test has reduced due to the word embeddings and size being limited in knowledge that was given to it. While creating embeddings for the test set, we were able to see that a lot of the words were not found in the vocabulary which is why there were no embeddings for them and hence we could not extract knowledge from them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
